{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 200,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 10,\n",
    "    'log_interval': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform_dataset():\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "            transforms.Resize((32,32)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    loaded_trdata = datasets.MNIST('../data', train = True, download = True, transform = trans)\n",
    "    loaded_tsdata = datasets.MNIST('../data', train = False, transform = trans)\n",
    "    trdata = DataLoader(loaded_trdata, batch_size=params['batch_size'], shuffle=True)\n",
    "    tsdata = DataLoader(loaded_tsdata, batch_size=params['batch_size'], shuffle = False)\n",
    "    \n",
    "    return trdata, tsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    Input - 1x32x32\n",
    "    C1 - 6@28x28 (5x5 kernel)\n",
    "    ReLU\n",
    "    S2 - 6@14x14 (2x2 kernel, stride 2) Subsampling\n",
    "    C3 - 16@10x10 (5x5 kernel)\n",
    "    ReLU\n",
    "    S4 - 16@5x5 (2x2 kernel, stride 2) Subsampling\n",
    "    C5 - 120@1x1 (5x5 kernel)\n",
    "    F6 - 84\n",
    "    ReLU\n",
    "    F7 - 10 (Output)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.clayer1 = nn.Sequential(\\\n",
    "                                    nn.Conv2d(1, 6, kernel_size = 5, stride = 1),\\\n",
    "                                    nn.ReLU(),\\\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.clayer2 = nn.Sequential(\\\n",
    "                            nn.Conv2d(6, 16, kernel_size = 5, stride = 1),\\\n",
    "                            nn.ReLU(),\\\n",
    "                            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.fully_connected_clayer = nn.Sequential(\\\n",
    "                            nn.Conv2d(16, 120, kernel_size = 5),\\\n",
    "                            nn.ReLU())\n",
    "        #The fifth layer (C5) is a fully connected convolutional layer with 120 feature \n",
    "        #maps each of size 1Ã—1. Each of the 120 units in C5 is connected to all the 400 \n",
    "        #nodes (5x5x16) in the fourth layer S4.\n",
    "        self.fc1 = nn.Linear(120,84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.clayer1(x)\n",
    "        x = self.clayer2(x)\n",
    "        x = self.fully_connected_clayer(x)\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (clayer1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (clayer2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fully_connected_clayer): Sequential(\n",
      "    (0): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_and_transform_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandipan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 [0/60000] (0 %)  Loss: 2.301035  Train_acc: 8.000000\n",
      "Train Epoch : 1 [2000/60000] (3 %)  Loss: 2.087705  Train_acc: 53.000000\n",
      "Train Epoch : 1 [4000/60000] (7 %)  Loss: 1.397215  Train_acc: 73.500000\n",
      "Train Epoch : 1 [6000/60000] (10 %)  Loss: 0.771373  Train_acc: 80.000000\n",
      "Train Epoch : 1 [8000/60000] (13 %)  Loss: 0.555987  Train_acc: 83.500000\n",
      "Train Epoch : 1 [10000/60000] (17 %)  Loss: 0.435411  Train_acc: 86.500000\n",
      "Train Epoch : 1 [12000/60000] (20 %)  Loss: 0.427415  Train_acc: 84.500000\n",
      "Train Epoch : 1 [14000/60000] (23 %)  Loss: 0.339552  Train_acc: 90.500000\n",
      "Train Epoch : 1 [16000/60000] (27 %)  Loss: 0.416059  Train_acc: 88.500000\n",
      "Train Epoch : 1 [18000/60000] (30 %)  Loss: 0.324899  Train_acc: 91.000000\n",
      "Train Epoch : 1 [20000/60000] (33 %)  Loss: 0.294638  Train_acc: 90.000000\n",
      "Train Epoch : 1 [22000/60000] (37 %)  Loss: 0.237819  Train_acc: 93.000000\n",
      "Train Epoch : 1 [24000/60000] (40 %)  Loss: 0.170055  Train_acc: 97.000000\n",
      "Train Epoch : 1 [26000/60000] (43 %)  Loss: 0.199377  Train_acc: 94.500000\n",
      "Train Epoch : 1 [28000/60000] (47 %)  Loss: 0.193099  Train_acc: 94.000000\n",
      "Train Epoch : 1 [30000/60000] (50 %)  Loss: 0.173383  Train_acc: 95.500000\n",
      "Train Epoch : 1 [32000/60000] (53 %)  Loss: 0.214443  Train_acc: 94.000000\n",
      "Train Epoch : 1 [34000/60000] (57 %)  Loss: 0.154861  Train_acc: 97.000000\n",
      "Train Epoch : 1 [36000/60000] (60 %)  Loss: 0.143515  Train_acc: 95.000000\n",
      "Train Epoch : 1 [38000/60000] (63 %)  Loss: 0.140137  Train_acc: 95.500000\n",
      "Train Epoch : 1 [40000/60000] (67 %)  Loss: 0.185540  Train_acc: 95.000000\n",
      "Train Epoch : 1 [42000/60000] (70 %)  Loss: 0.188107  Train_acc: 95.500000\n",
      "Train Epoch : 1 [44000/60000] (73 %)  Loss: 0.070359  Train_acc: 98.000000\n",
      "Train Epoch : 1 [46000/60000] (77 %)  Loss: 0.072842  Train_acc: 97.500000\n",
      "Train Epoch : 1 [48000/60000] (80 %)  Loss: 0.064823  Train_acc: 98.000000\n",
      "Train Epoch : 1 [50000/60000] (83 %)  Loss: 0.154756  Train_acc: 95.500000\n",
      "Train Epoch : 1 [52000/60000] (87 %)  Loss: 0.104666  Train_acc: 97.000000\n",
      "Train Epoch : 1 [54000/60000] (90 %)  Loss: 0.085331  Train_acc: 97.500000\n",
      "Train Epoch : 1 [56000/60000] (93 %)  Loss: 0.159196  Train_acc: 95.000000\n",
      "Train Epoch : 1 [58000/60000] (97 %)  Loss: 0.070581  Train_acc: 97.500000\n",
      "Train Epoch : 2 [0/60000] (0 %)  Loss: 0.053896  Train_acc: 98.500000\n",
      "Train Epoch : 2 [2000/60000] (3 %)  Loss: 0.097832  Train_acc: 97.000000\n",
      "Train Epoch : 2 [4000/60000] (7 %)  Loss: 0.125993  Train_acc: 97.500000\n",
      "Train Epoch : 2 [6000/60000] (10 %)  Loss: 0.071048  Train_acc: 97.500000\n",
      "Train Epoch : 2 [8000/60000] (13 %)  Loss: 0.213073  Train_acc: 94.500000\n",
      "Train Epoch : 2 [10000/60000] (17 %)  Loss: 0.103523  Train_acc: 97.000000\n",
      "Train Epoch : 2 [12000/60000] (20 %)  Loss: 0.087442  Train_acc: 97.000000\n",
      "Train Epoch : 2 [14000/60000] (23 %)  Loss: 0.052119  Train_acc: 97.500000\n",
      "Train Epoch : 2 [16000/60000] (27 %)  Loss: 0.083060  Train_acc: 97.000000\n",
      "Train Epoch : 2 [18000/60000] (30 %)  Loss: 0.061950  Train_acc: 98.500000\n",
      "Train Epoch : 2 [20000/60000] (33 %)  Loss: 0.109974  Train_acc: 98.000000\n",
      "Train Epoch : 2 [22000/60000] (37 %)  Loss: 0.144988  Train_acc: 95.500000\n",
      "Train Epoch : 2 [24000/60000] (40 %)  Loss: 0.107025  Train_acc: 98.000000\n",
      "Train Epoch : 2 [26000/60000] (43 %)  Loss: 0.110650  Train_acc: 95.500000\n",
      "Train Epoch : 2 [28000/60000] (47 %)  Loss: 0.082650  Train_acc: 97.000000\n",
      "Train Epoch : 2 [30000/60000] (50 %)  Loss: 0.051988  Train_acc: 98.500000\n",
      "Train Epoch : 2 [32000/60000] (53 %)  Loss: 0.125787  Train_acc: 96.500000\n",
      "Train Epoch : 2 [34000/60000] (57 %)  Loss: 0.119101  Train_acc: 97.000000\n",
      "Train Epoch : 2 [36000/60000] (60 %)  Loss: 0.045032  Train_acc: 97.500000\n",
      "Train Epoch : 2 [38000/60000] (63 %)  Loss: 0.037322  Train_acc: 99.000000\n",
      "Train Epoch : 2 [40000/60000] (67 %)  Loss: 0.056549  Train_acc: 97.500000\n",
      "Train Epoch : 2 [42000/60000] (70 %)  Loss: 0.074331  Train_acc: 97.500000\n",
      "Train Epoch : 2 [44000/60000] (73 %)  Loss: 0.062661  Train_acc: 98.500000\n",
      "Train Epoch : 2 [46000/60000] (77 %)  Loss: 0.077016  Train_acc: 98.000000\n",
      "Train Epoch : 2 [48000/60000] (80 %)  Loss: 0.116350  Train_acc: 96.500000\n",
      "Train Epoch : 2 [50000/60000] (83 %)  Loss: 0.038893  Train_acc: 98.500000\n",
      "Train Epoch : 2 [52000/60000] (87 %)  Loss: 0.053978  Train_acc: 97.500000\n",
      "Train Epoch : 2 [54000/60000] (90 %)  Loss: 0.081478  Train_acc: 97.000000\n",
      "Train Epoch : 2 [56000/60000] (93 %)  Loss: 0.043919  Train_acc: 99.000000\n",
      "Train Epoch : 2 [58000/60000] (97 %)  Loss: 0.052450  Train_acc: 97.500000\n",
      "Train Epoch : 3 [0/60000] (0 %)  Loss: 0.089366  Train_acc: 97.500000\n",
      "Train Epoch : 3 [2000/60000] (3 %)  Loss: 0.083049  Train_acc: 97.000000\n",
      "Train Epoch : 3 [4000/60000] (7 %)  Loss: 0.083477  Train_acc: 98.000000\n",
      "Train Epoch : 3 [6000/60000] (10 %)  Loss: 0.074671  Train_acc: 97.500000\n",
      "Train Epoch : 3 [8000/60000] (13 %)  Loss: 0.043590  Train_acc: 98.500000\n",
      "Train Epoch : 3 [10000/60000] (17 %)  Loss: 0.046589  Train_acc: 98.000000\n",
      "Train Epoch : 3 [12000/60000] (20 %)  Loss: 0.037680  Train_acc: 99.000000\n",
      "Train Epoch : 3 [14000/60000] (23 %)  Loss: 0.171268  Train_acc: 97.500000\n",
      "Train Epoch : 3 [16000/60000] (27 %)  Loss: 0.072359  Train_acc: 98.000000\n",
      "Train Epoch : 3 [18000/60000] (30 %)  Loss: 0.072148  Train_acc: 97.000000\n",
      "Train Epoch : 3 [20000/60000] (33 %)  Loss: 0.082362  Train_acc: 96.500000\n",
      "Train Epoch : 3 [22000/60000] (37 %)  Loss: 0.028323  Train_acc: 99.500000\n",
      "Train Epoch : 3 [24000/60000] (40 %)  Loss: 0.057791  Train_acc: 98.000000\n",
      "Train Epoch : 3 [26000/60000] (43 %)  Loss: 0.090635  Train_acc: 98.000000\n",
      "Train Epoch : 3 [28000/60000] (47 %)  Loss: 0.031002  Train_acc: 99.000000\n",
      "Train Epoch : 3 [30000/60000] (50 %)  Loss: 0.050380  Train_acc: 98.500000\n",
      "Train Epoch : 3 [32000/60000] (53 %)  Loss: 0.043722  Train_acc: 98.000000\n",
      "Train Epoch : 3 [34000/60000] (57 %)  Loss: 0.076176  Train_acc: 98.000000\n",
      "Train Epoch : 3 [36000/60000] (60 %)  Loss: 0.041479  Train_acc: 99.000000\n",
      "Train Epoch : 3 [38000/60000] (63 %)  Loss: 0.073219  Train_acc: 98.000000\n",
      "Train Epoch : 3 [40000/60000] (67 %)  Loss: 0.034500  Train_acc: 99.000000\n",
      "Train Epoch : 3 [42000/60000] (70 %)  Loss: 0.014336  Train_acc: 100.000000\n",
      "Train Epoch : 3 [44000/60000] (73 %)  Loss: 0.068595  Train_acc: 97.000000\n",
      "Train Epoch : 3 [46000/60000] (77 %)  Loss: 0.044692  Train_acc: 98.000000\n",
      "Train Epoch : 3 [48000/60000] (80 %)  Loss: 0.031148  Train_acc: 99.000000\n",
      "Train Epoch : 3 [50000/60000] (83 %)  Loss: 0.063836  Train_acc: 98.500000\n",
      "Train Epoch : 3 [52000/60000] (87 %)  Loss: 0.033237  Train_acc: 99.000000\n",
      "Train Epoch : 3 [54000/60000] (90 %)  Loss: 0.009565  Train_acc: 99.500000\n",
      "Train Epoch : 3 [56000/60000] (93 %)  Loss: 0.052717  Train_acc: 98.500000\n",
      "Train Epoch : 3 [58000/60000] (97 %)  Loss: 0.028819  Train_acc: 99.000000\n",
      "Train Epoch : 4 [0/60000] (0 %)  Loss: 0.106592  Train_acc: 97.000000\n",
      "Train Epoch : 4 [2000/60000] (3 %)  Loss: 0.049708  Train_acc: 97.500000\n",
      "Train Epoch : 4 [4000/60000] (7 %)  Loss: 0.076321  Train_acc: 98.000000\n",
      "Train Epoch : 4 [6000/60000] (10 %)  Loss: 0.080575  Train_acc: 97.000000\n",
      "Train Epoch : 4 [8000/60000] (13 %)  Loss: 0.040813  Train_acc: 99.000000\n",
      "Train Epoch : 4 [10000/60000] (17 %)  Loss: 0.038009  Train_acc: 99.000000\n",
      "Train Epoch : 4 [12000/60000] (20 %)  Loss: 0.029854  Train_acc: 99.000000\n",
      "Train Epoch : 4 [14000/60000] (23 %)  Loss: 0.032480  Train_acc: 99.000000\n",
      "Train Epoch : 4 [16000/60000] (27 %)  Loss: 0.021229  Train_acc: 99.500000\n",
      "Train Epoch : 4 [18000/60000] (30 %)  Loss: 0.036220  Train_acc: 99.000000\n",
      "Train Epoch : 4 [20000/60000] (33 %)  Loss: 0.028121  Train_acc: 99.000000\n",
      "Train Epoch : 4 [22000/60000] (37 %)  Loss: 0.023883  Train_acc: 99.500000\n",
      "Train Epoch : 4 [24000/60000] (40 %)  Loss: 0.055111  Train_acc: 98.500000\n",
      "Train Epoch : 4 [26000/60000] (43 %)  Loss: 0.021328  Train_acc: 100.000000\n",
      "Train Epoch : 4 [28000/60000] (47 %)  Loss: 0.013694  Train_acc: 99.500000\n",
      "Train Epoch : 4 [30000/60000] (50 %)  Loss: 0.034918  Train_acc: 99.000000\n",
      "Train Epoch : 4 [32000/60000] (53 %)  Loss: 0.063175  Train_acc: 98.000000\n",
      "Train Epoch : 4 [34000/60000] (57 %)  Loss: 0.017333  Train_acc: 99.500000\n",
      "Train Epoch : 4 [36000/60000] (60 %)  Loss: 0.056378  Train_acc: 98.000000\n",
      "Train Epoch : 4 [38000/60000] (63 %)  Loss: 0.027087  Train_acc: 99.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 4 [40000/60000] (67 %)  Loss: 0.050799  Train_acc: 99.500000\n",
      "Train Epoch : 4 [42000/60000] (70 %)  Loss: 0.074542  Train_acc: 97.000000\n",
      "Train Epoch : 4 [44000/60000] (73 %)  Loss: 0.033059  Train_acc: 99.500000\n",
      "Train Epoch : 4 [46000/60000] (77 %)  Loss: 0.078786  Train_acc: 97.500000\n",
      "Train Epoch : 4 [48000/60000] (80 %)  Loss: 0.050011  Train_acc: 99.000000\n",
      "Train Epoch : 4 [50000/60000] (83 %)  Loss: 0.028542  Train_acc: 99.500000\n",
      "Train Epoch : 4 [52000/60000] (87 %)  Loss: 0.063381  Train_acc: 98.500000\n",
      "Train Epoch : 4 [54000/60000] (90 %)  Loss: 0.101269  Train_acc: 98.000000\n",
      "Train Epoch : 4 [56000/60000] (93 %)  Loss: 0.025558  Train_acc: 99.500000\n",
      "Train Epoch : 4 [58000/60000] (97 %)  Loss: 0.046320  Train_acc: 98.500000\n",
      "Train Epoch : 5 [0/60000] (0 %)  Loss: 0.044064  Train_acc: 99.000000\n",
      "Train Epoch : 5 [2000/60000] (3 %)  Loss: 0.028953  Train_acc: 99.500000\n",
      "Train Epoch : 5 [4000/60000] (7 %)  Loss: 0.011497  Train_acc: 100.000000\n",
      "Train Epoch : 5 [6000/60000] (10 %)  Loss: 0.021440  Train_acc: 99.000000\n",
      "Train Epoch : 5 [8000/60000] (13 %)  Loss: 0.038734  Train_acc: 99.000000\n",
      "Train Epoch : 5 [10000/60000] (17 %)  Loss: 0.016731  Train_acc: 99.500000\n",
      "Train Epoch : 5 [12000/60000] (20 %)  Loss: 0.019714  Train_acc: 99.500000\n",
      "Train Epoch : 5 [14000/60000] (23 %)  Loss: 0.026496  Train_acc: 99.000000\n",
      "Train Epoch : 5 [16000/60000] (27 %)  Loss: 0.057757  Train_acc: 97.000000\n",
      "Train Epoch : 5 [18000/60000] (30 %)  Loss: 0.037793  Train_acc: 99.000000\n",
      "Train Epoch : 5 [20000/60000] (33 %)  Loss: 0.017294  Train_acc: 99.500000\n",
      "Train Epoch : 5 [22000/60000] (37 %)  Loss: 0.064742  Train_acc: 98.000000\n",
      "Train Epoch : 5 [24000/60000] (40 %)  Loss: 0.075937  Train_acc: 97.500000\n",
      "Train Epoch : 5 [26000/60000] (43 %)  Loss: 0.032364  Train_acc: 98.500000\n",
      "Train Epoch : 5 [28000/60000] (47 %)  Loss: 0.050872  Train_acc: 98.000000\n",
      "Train Epoch : 5 [30000/60000] (50 %)  Loss: 0.030099  Train_acc: 98.500000\n",
      "Train Epoch : 5 [32000/60000] (53 %)  Loss: 0.062944  Train_acc: 98.500000\n",
      "Train Epoch : 5 [34000/60000] (57 %)  Loss: 0.095163  Train_acc: 98.000000\n",
      "Train Epoch : 5 [36000/60000] (60 %)  Loss: 0.049325  Train_acc: 99.000000\n",
      "Train Epoch : 5 [38000/60000] (63 %)  Loss: 0.054757  Train_acc: 97.500000\n",
      "Train Epoch : 5 [40000/60000] (67 %)  Loss: 0.022296  Train_acc: 99.000000\n",
      "Train Epoch : 5 [42000/60000] (70 %)  Loss: 0.017042  Train_acc: 100.000000\n",
      "Train Epoch : 5 [44000/60000] (73 %)  Loss: 0.087177  Train_acc: 96.000000\n",
      "Train Epoch : 5 [46000/60000] (77 %)  Loss: 0.026404  Train_acc: 99.000000\n",
      "Train Epoch : 5 [48000/60000] (80 %)  Loss: 0.057734  Train_acc: 97.500000\n",
      "Train Epoch : 5 [50000/60000] (83 %)  Loss: 0.047096  Train_acc: 98.500000\n",
      "Train Epoch : 5 [52000/60000] (87 %)  Loss: 0.031495  Train_acc: 98.500000\n",
      "Train Epoch : 5 [54000/60000] (90 %)  Loss: 0.071636  Train_acc: 98.500000\n",
      "Train Epoch : 5 [56000/60000] (93 %)  Loss: 0.024230  Train_acc: 99.500000\n",
      "Train Epoch : 5 [58000/60000] (97 %)  Loss: 0.088401  Train_acc: 97.500000\n",
      "Train Epoch : 6 [0/60000] (0 %)  Loss: 0.022305  Train_acc: 99.000000\n",
      "Train Epoch : 6 [2000/60000] (3 %)  Loss: 0.024952  Train_acc: 98.500000\n",
      "Train Epoch : 6 [4000/60000] (7 %)  Loss: 0.026486  Train_acc: 99.500000\n",
      "Train Epoch : 6 [6000/60000] (10 %)  Loss: 0.046746  Train_acc: 98.500000\n",
      "Train Epoch : 6 [8000/60000] (13 %)  Loss: 0.012382  Train_acc: 100.000000\n",
      "Train Epoch : 6 [10000/60000] (17 %)  Loss: 0.021434  Train_acc: 99.500000\n",
      "Train Epoch : 6 [12000/60000] (20 %)  Loss: 0.047457  Train_acc: 98.000000\n",
      "Train Epoch : 6 [14000/60000] (23 %)  Loss: 0.031195  Train_acc: 99.000000\n",
      "Train Epoch : 6 [16000/60000] (27 %)  Loss: 0.048819  Train_acc: 98.500000\n",
      "Train Epoch : 6 [18000/60000] (30 %)  Loss: 0.013172  Train_acc: 99.500000\n",
      "Train Epoch : 6 [20000/60000] (33 %)  Loss: 0.028220  Train_acc: 98.500000\n",
      "Train Epoch : 6 [22000/60000] (37 %)  Loss: 0.044773  Train_acc: 98.500000\n",
      "Train Epoch : 6 [24000/60000] (40 %)  Loss: 0.007723  Train_acc: 100.000000\n",
      "Train Epoch : 6 [26000/60000] (43 %)  Loss: 0.049159  Train_acc: 98.500000\n",
      "Train Epoch : 6 [28000/60000] (47 %)  Loss: 0.043059  Train_acc: 98.500000\n",
      "Train Epoch : 6 [30000/60000] (50 %)  Loss: 0.045378  Train_acc: 99.000000\n",
      "Train Epoch : 6 [32000/60000] (53 %)  Loss: 0.078387  Train_acc: 98.000000\n",
      "Train Epoch : 6 [34000/60000] (57 %)  Loss: 0.042148  Train_acc: 98.000000\n",
      "Train Epoch : 6 [36000/60000] (60 %)  Loss: 0.015150  Train_acc: 100.000000\n",
      "Train Epoch : 6 [38000/60000] (63 %)  Loss: 0.033009  Train_acc: 99.000000\n",
      "Train Epoch : 6 [40000/60000] (67 %)  Loss: 0.007228  Train_acc: 100.000000\n",
      "Train Epoch : 6 [42000/60000] (70 %)  Loss: 0.044774  Train_acc: 98.500000\n",
      "Train Epoch : 6 [44000/60000] (73 %)  Loss: 0.011421  Train_acc: 100.000000\n",
      "Train Epoch : 6 [46000/60000] (77 %)  Loss: 0.017235  Train_acc: 99.500000\n",
      "Train Epoch : 6 [48000/60000] (80 %)  Loss: 0.016303  Train_acc: 99.000000\n",
      "Train Epoch : 6 [50000/60000] (83 %)  Loss: 0.004390  Train_acc: 100.000000\n",
      "Train Epoch : 6 [52000/60000] (87 %)  Loss: 0.010148  Train_acc: 100.000000\n",
      "Train Epoch : 6 [54000/60000] (90 %)  Loss: 0.018386  Train_acc: 99.000000\n",
      "Train Epoch : 6 [56000/60000] (93 %)  Loss: 0.010989  Train_acc: 100.000000\n",
      "Train Epoch : 6 [58000/60000] (97 %)  Loss: 0.035640  Train_acc: 98.000000\n",
      "Train Epoch : 7 [0/60000] (0 %)  Loss: 0.054249  Train_acc: 98.500000\n",
      "Train Epoch : 7 [2000/60000] (3 %)  Loss: 0.035113  Train_acc: 98.000000\n",
      "Train Epoch : 7 [4000/60000] (7 %)  Loss: 0.056859  Train_acc: 98.000000\n",
      "Train Epoch : 7 [6000/60000] (10 %)  Loss: 0.019776  Train_acc: 100.000000\n",
      "Train Epoch : 7 [8000/60000] (13 %)  Loss: 0.030625  Train_acc: 98.500000\n",
      "Train Epoch : 7 [10000/60000] (17 %)  Loss: 0.018318  Train_acc: 98.500000\n",
      "Train Epoch : 7 [12000/60000] (20 %)  Loss: 0.052827  Train_acc: 98.000000\n",
      "Train Epoch : 7 [14000/60000] (23 %)  Loss: 0.029214  Train_acc: 99.000000\n",
      "Train Epoch : 7 [16000/60000] (27 %)  Loss: 0.021822  Train_acc: 99.500000\n",
      "Train Epoch : 7 [18000/60000] (30 %)  Loss: 0.020620  Train_acc: 99.000000\n",
      "Train Epoch : 7 [20000/60000] (33 %)  Loss: 0.065798  Train_acc: 98.500000\n",
      "Train Epoch : 7 [22000/60000] (37 %)  Loss: 0.040539  Train_acc: 98.500000\n",
      "Train Epoch : 7 [24000/60000] (40 %)  Loss: 0.018869  Train_acc: 99.000000\n",
      "Train Epoch : 7 [26000/60000] (43 %)  Loss: 0.016191  Train_acc: 99.500000\n",
      "Train Epoch : 7 [28000/60000] (47 %)  Loss: 0.047852  Train_acc: 99.000000\n",
      "Train Epoch : 7 [30000/60000] (50 %)  Loss: 0.062673  Train_acc: 98.000000\n",
      "Train Epoch : 7 [32000/60000] (53 %)  Loss: 0.024307  Train_acc: 99.000000\n",
      "Train Epoch : 7 [34000/60000] (57 %)  Loss: 0.014348  Train_acc: 100.000000\n",
      "Train Epoch : 7 [36000/60000] (60 %)  Loss: 0.049198  Train_acc: 98.500000\n",
      "Train Epoch : 7 [38000/60000] (63 %)  Loss: 0.014522  Train_acc: 99.500000\n",
      "Train Epoch : 7 [40000/60000] (67 %)  Loss: 0.018233  Train_acc: 99.500000\n",
      "Train Epoch : 7 [42000/60000] (70 %)  Loss: 0.009655  Train_acc: 100.000000\n",
      "Train Epoch : 7 [44000/60000] (73 %)  Loss: 0.025725  Train_acc: 99.500000\n",
      "Train Epoch : 7 [46000/60000] (77 %)  Loss: 0.043990  Train_acc: 98.000000\n",
      "Train Epoch : 7 [48000/60000] (80 %)  Loss: 0.075880  Train_acc: 98.000000\n",
      "Train Epoch : 7 [50000/60000] (83 %)  Loss: 0.023401  Train_acc: 99.000000\n",
      "Train Epoch : 7 [52000/60000] (87 %)  Loss: 0.024134  Train_acc: 99.500000\n",
      "Train Epoch : 7 [54000/60000] (90 %)  Loss: 0.026711  Train_acc: 99.000000\n",
      "Train Epoch : 7 [56000/60000] (93 %)  Loss: 0.003017  Train_acc: 100.000000\n",
      "Train Epoch : 7 [58000/60000] (97 %)  Loss: 0.005919  Train_acc: 100.000000\n",
      "Train Epoch : 8 [0/60000] (0 %)  Loss: 0.012133  Train_acc: 99.000000\n",
      "Train Epoch : 8 [2000/60000] (3 %)  Loss: 0.014769  Train_acc: 99.500000\n",
      "Train Epoch : 8 [4000/60000] (7 %)  Loss: 0.033928  Train_acc: 99.000000\n",
      "Train Epoch : 8 [6000/60000] (10 %)  Loss: 0.025847  Train_acc: 99.500000\n",
      "Train Epoch : 8 [8000/60000] (13 %)  Loss: 0.043110  Train_acc: 98.000000\n",
      "Train Epoch : 8 [10000/60000] (17 %)  Loss: 0.007478  Train_acc: 99.500000\n",
      "Train Epoch : 8 [12000/60000] (20 %)  Loss: 0.008071  Train_acc: 100.000000\n",
      "Train Epoch : 8 [14000/60000] (23 %)  Loss: 0.021684  Train_acc: 99.500000\n",
      "Train Epoch : 8 [16000/60000] (27 %)  Loss: 0.009263  Train_acc: 99.500000\n",
      "Train Epoch : 8 [18000/60000] (30 %)  Loss: 0.073787  Train_acc: 98.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 8 [20000/60000] (33 %)  Loss: 0.022246  Train_acc: 99.000000\n",
      "Train Epoch : 8 [22000/60000] (37 %)  Loss: 0.033699  Train_acc: 99.000000\n",
      "Train Epoch : 8 [24000/60000] (40 %)  Loss: 0.004226  Train_acc: 100.000000\n",
      "Train Epoch : 8 [26000/60000] (43 %)  Loss: 0.018505  Train_acc: 99.500000\n",
      "Train Epoch : 8 [28000/60000] (47 %)  Loss: 0.021613  Train_acc: 98.500000\n",
      "Train Epoch : 8 [30000/60000] (50 %)  Loss: 0.019382  Train_acc: 99.000000\n",
      "Train Epoch : 8 [32000/60000] (53 %)  Loss: 0.044150  Train_acc: 98.500000\n",
      "Train Epoch : 8 [34000/60000] (57 %)  Loss: 0.013950  Train_acc: 100.000000\n",
      "Train Epoch : 8 [36000/60000] (60 %)  Loss: 0.081864  Train_acc: 98.000000\n",
      "Train Epoch : 8 [38000/60000] (63 %)  Loss: 0.012259  Train_acc: 99.500000\n",
      "Train Epoch : 8 [40000/60000] (67 %)  Loss: 0.007060  Train_acc: 100.000000\n",
      "Train Epoch : 8 [42000/60000] (70 %)  Loss: 0.018263  Train_acc: 100.000000\n",
      "Train Epoch : 8 [44000/60000] (73 %)  Loss: 0.011471  Train_acc: 100.000000\n",
      "Train Epoch : 8 [46000/60000] (77 %)  Loss: 0.005272  Train_acc: 100.000000\n",
      "Train Epoch : 8 [48000/60000] (80 %)  Loss: 0.014762  Train_acc: 99.500000\n",
      "Train Epoch : 8 [50000/60000] (83 %)  Loss: 0.015351  Train_acc: 99.000000\n",
      "Train Epoch : 8 [52000/60000] (87 %)  Loss: 0.036915  Train_acc: 98.500000\n",
      "Train Epoch : 8 [54000/60000] (90 %)  Loss: 0.001676  Train_acc: 100.000000\n",
      "Train Epoch : 8 [56000/60000] (93 %)  Loss: 0.019955  Train_acc: 99.500000\n",
      "Train Epoch : 8 [58000/60000] (97 %)  Loss: 0.061602  Train_acc: 98.500000\n",
      "Train Epoch : 9 [0/60000] (0 %)  Loss: 0.035591  Train_acc: 98.500000\n",
      "Train Epoch : 9 [2000/60000] (3 %)  Loss: 0.045915  Train_acc: 98.500000\n",
      "Train Epoch : 9 [4000/60000] (7 %)  Loss: 0.014222  Train_acc: 100.000000\n",
      "Train Epoch : 9 [6000/60000] (10 %)  Loss: 0.034898  Train_acc: 98.500000\n",
      "Train Epoch : 9 [8000/60000] (13 %)  Loss: 0.025531  Train_acc: 98.500000\n",
      "Train Epoch : 9 [10000/60000] (17 %)  Loss: 0.031465  Train_acc: 99.500000\n",
      "Train Epoch : 9 [12000/60000] (20 %)  Loss: 0.007170  Train_acc: 100.000000\n",
      "Train Epoch : 9 [14000/60000] (23 %)  Loss: 0.024517  Train_acc: 99.000000\n",
      "Train Epoch : 9 [16000/60000] (27 %)  Loss: 0.005632  Train_acc: 100.000000\n",
      "Train Epoch : 9 [18000/60000] (30 %)  Loss: 0.017814  Train_acc: 99.500000\n",
      "Train Epoch : 9 [20000/60000] (33 %)  Loss: 0.039688  Train_acc: 98.000000\n",
      "Train Epoch : 9 [22000/60000] (37 %)  Loss: 0.036393  Train_acc: 99.000000\n",
      "Train Epoch : 9 [24000/60000] (40 %)  Loss: 0.005697  Train_acc: 100.000000\n",
      "Train Epoch : 9 [26000/60000] (43 %)  Loss: 0.019168  Train_acc: 99.500000\n",
      "Train Epoch : 9 [28000/60000] (47 %)  Loss: 0.006226  Train_acc: 99.500000\n",
      "Train Epoch : 9 [30000/60000] (50 %)  Loss: 0.007905  Train_acc: 100.000000\n",
      "Train Epoch : 9 [32000/60000] (53 %)  Loss: 0.090313  Train_acc: 97.000000\n",
      "Train Epoch : 9 [34000/60000] (57 %)  Loss: 0.025534  Train_acc: 99.500000\n",
      "Train Epoch : 9 [36000/60000] (60 %)  Loss: 0.007218  Train_acc: 100.000000\n",
      "Train Epoch : 9 [38000/60000] (63 %)  Loss: 0.044265  Train_acc: 98.500000\n",
      "Train Epoch : 9 [40000/60000] (67 %)  Loss: 0.012529  Train_acc: 100.000000\n",
      "Train Epoch : 9 [42000/60000] (70 %)  Loss: 0.009505  Train_acc: 99.500000\n",
      "Train Epoch : 9 [44000/60000] (73 %)  Loss: 0.014695  Train_acc: 99.500000\n",
      "Train Epoch : 9 [46000/60000] (77 %)  Loss: 0.030607  Train_acc: 98.500000\n",
      "Train Epoch : 9 [48000/60000] (80 %)  Loss: 0.016335  Train_acc: 99.500000\n",
      "Train Epoch : 9 [50000/60000] (83 %)  Loss: 0.009700  Train_acc: 100.000000\n",
      "Train Epoch : 9 [52000/60000] (87 %)  Loss: 0.010729  Train_acc: 99.500000\n",
      "Train Epoch : 9 [54000/60000] (90 %)  Loss: 0.028254  Train_acc: 99.000000\n",
      "Train Epoch : 9 [56000/60000] (93 %)  Loss: 0.033237  Train_acc: 99.000000\n",
      "Train Epoch : 9 [58000/60000] (97 %)  Loss: 0.035430  Train_acc: 99.000000\n",
      "Train Epoch : 10 [0/60000] (0 %)  Loss: 0.037018  Train_acc: 99.500000\n",
      "Train Epoch : 10 [2000/60000] (3 %)  Loss: 0.014901  Train_acc: 99.000000\n",
      "Train Epoch : 10 [4000/60000] (7 %)  Loss: 0.010702  Train_acc: 99.500000\n",
      "Train Epoch : 10 [6000/60000] (10 %)  Loss: 0.033489  Train_acc: 98.500000\n",
      "Train Epoch : 10 [8000/60000] (13 %)  Loss: 0.008147  Train_acc: 100.000000\n",
      "Train Epoch : 10 [10000/60000] (17 %)  Loss: 0.002537  Train_acc: 100.000000\n",
      "Train Epoch : 10 [12000/60000] (20 %)  Loss: 0.021101  Train_acc: 98.500000\n",
      "Train Epoch : 10 [14000/60000] (23 %)  Loss: 0.001402  Train_acc: 100.000000\n",
      "Train Epoch : 10 [16000/60000] (27 %)  Loss: 0.050743  Train_acc: 98.500000\n",
      "Train Epoch : 10 [18000/60000] (30 %)  Loss: 0.025574  Train_acc: 99.500000\n",
      "Train Epoch : 10 [20000/60000] (33 %)  Loss: 0.016291  Train_acc: 99.500000\n",
      "Train Epoch : 10 [22000/60000] (37 %)  Loss: 0.006503  Train_acc: 99.500000\n",
      "Train Epoch : 10 [24000/60000] (40 %)  Loss: 0.020688  Train_acc: 99.000000\n",
      "Train Epoch : 10 [26000/60000] (43 %)  Loss: 0.028265  Train_acc: 99.000000\n",
      "Train Epoch : 10 [28000/60000] (47 %)  Loss: 0.005448  Train_acc: 100.000000\n",
      "Train Epoch : 10 [30000/60000] (50 %)  Loss: 0.026490  Train_acc: 99.000000\n",
      "Train Epoch : 10 [32000/60000] (53 %)  Loss: 0.005779  Train_acc: 100.000000\n",
      "Train Epoch : 10 [34000/60000] (57 %)  Loss: 0.051237  Train_acc: 97.500000\n",
      "Train Epoch : 10 [36000/60000] (60 %)  Loss: 0.002318  Train_acc: 100.000000\n",
      "Train Epoch : 10 [38000/60000] (63 %)  Loss: 0.015673  Train_acc: 99.500000\n",
      "Train Epoch : 10 [40000/60000] (67 %)  Loss: 0.030663  Train_acc: 99.000000\n",
      "Train Epoch : 10 [42000/60000] (70 %)  Loss: 0.007957  Train_acc: 99.500000\n",
      "Train Epoch : 10 [44000/60000] (73 %)  Loss: 0.035008  Train_acc: 98.500000\n",
      "Train Epoch : 10 [46000/60000] (77 %)  Loss: 0.023308  Train_acc: 99.500000\n",
      "Train Epoch : 10 [48000/60000] (80 %)  Loss: 0.009601  Train_acc: 99.000000\n",
      "Train Epoch : 10 [50000/60000] (83 %)  Loss: 0.026071  Train_acc: 99.000000\n",
      "Train Epoch : 10 [52000/60000] (87 %)  Loss: 0.003853  Train_acc: 100.000000\n",
      "Train Epoch : 10 [54000/60000] (90 %)  Loss: 0.017631  Train_acc: 99.500000\n",
      "Train Epoch : 10 [56000/60000] (93 %)  Loss: 0.002468  Train_acc: 100.000000\n",
      "Train Epoch : 10 [58000/60000] (97 %)  Loss: 0.010089  Train_acc: 99.500000\n"
     ]
    }
   ],
   "source": [
    "# training loop - keep storing the loss and accuracy too\n",
    "model.train()\n",
    "losses = []\n",
    "accs = []\n",
    "total_imgs_in_dataset = len(train_data.dataset)\n",
    "\"\"\"\n",
    "By default all the modules are initialized to train mode (self.training = True). \n",
    "Also be aware that some layers have different behavior during train/and evaluation\n",
    "(like BatchNorm, Dropout) so setting it matters. Also as a rule of thumb for \n",
    "programming in general, try to explicitly state your intent and set \n",
    "model.train() and model.eval() when necessary.\n",
    "\n",
    "\"\"\"\n",
    "for epoch in range(0, params['epochs']):\n",
    "    for batch_idx, (data, target) in enumerate(train_data):\n",
    "        \n",
    "        \n",
    "        # one forward pass\n",
    "        model_output = model(data)\n",
    "        #print(model_output)\n",
    "        train_loss = criterion(model_output, target)\n",
    "        losses.append(train_loss.item())\n",
    "        \n",
    "        # backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compare predictions\n",
    "        total_preds = target.size(0)\n",
    "        _, preds = torch.max(model_output.data, 1) # 1 indicates we need max values for each \"row\"\n",
    "        # Returns a namedtuple (values, indices) where values is the \n",
    "        # maximum value of each row of the input tensor in the given \n",
    "        # dimension dim. And indices is the index location of each maximum value found (argmax).\n",
    "        matched = (preds==target).sum().item()\n",
    "        accs.append(matched/total_preds)\n",
    "\n",
    "        if batch_idx % params['log_interval'] ==0:\n",
    "            processed_imgs = batch_idx*len(data) # no. of batches * no of images in each batch\n",
    "            percentage_processed = processed_imgs*100.0/total_imgs_in_dataset\n",
    "            print('Train Epoch : {} [{}/{}] ({:.0f} %)  Loss: {:.6f}  Train_acc: {:2f}'.format\\\n",
    "                 ((epoch+1), processed_imgs, total_imgs_in_dataset, percentage_processed,\\\n",
    "                 train_loss.item(), (matched/total_preds)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandipan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 99.0 %\n"
     ]
    }
   ],
   "source": [
    "#testing loop\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in test_data:\n",
    "        output = model(data)\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        correct += (preds == target).sum().item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss curve (training)\n",
    "noOfIters = [x for x in range(0,len(losses))]\n",
    "fig1 = plt.figure()\n",
    "plt.plot(noOfIters, losses, 'r', label = 'training loss')\n",
    "plt.title(\"Loss curve\")\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Loss');\n",
    "plt.xlabel('No. of iterations')\n",
    "plt.show()\n",
    "fig1.savefig('loss curve.png')\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "# accuracy curve (training)\n",
    "plt.plot(noOfIters, accs, 'b', label = 'accuracy')\n",
    "plt.title(\"Accuracy curve\")\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy ( values divided by 100)');\n",
    "plt.xlabel('No. of iterations')\n",
    "plt.savefig('accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
